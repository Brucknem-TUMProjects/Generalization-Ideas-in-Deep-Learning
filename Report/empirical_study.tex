%!TEX root=./report.tex
\section{Empirical study}
In this section we discuss the experimental results using the proposed measures and their implications on different phenomena seen in practice regarding the generalization behavior.
%
\subsection{Difference between true and random labeled data}
\begin{figure}
	\centering
	\includegraphics[width=0.32\linewidth]{vgg16/bokeh_plot.png}
	\includegraphics[width=0.32\linewidth]{vgg16/bokeh_plot(1).png}
	\includegraphics[width=0.32\linewidth]{vgg16/bokeh_plot(2).png}\\
	\includegraphics[width=0.32\linewidth]{vgg16/bokeh_plot(3).png}
	\includegraphics[width=0.32\linewidth]{vgg16/bokeh_plot(4).png}
	\caption{The proposed capacity measures calculated on the VGG model \cite{simonyan2014deep} after training on random (magenta) and true (blue) labeled subsets of CIFAR-10. We see only a small increase of the measures on true labels but a huge increase using random labels and the measures on random labels to be bigger for every subset. Reproduced from \cite{neyshabur2017exploring}.}	
	\label{fig:norms-paper}
\end{figure}
It is possible to obtain zero training error on random labels using the same architecture for which training with real labels leads to good generalization. We would expect the networks learned using real labels (and which generalizes well) to have much lower complexity, under the suggested measure, than those learned using random labels (and which obviously do not generalize well). \cite{neyshabur2017exploring} \par
%
\freff{fig:norms-paper} shows the results of \cite{neyshabur2017exploring}. We see that training the network on true labels (blue) only results in small increases of the norm-based capacity measures in comparison to the increases when training on random labels (magenta). As the network learns the true functional dependence between the input and output using true labels it only requires small increases in complexity as the subset size increases, whereas it requires more capacity for every newly seen data point when using random labels as it needs to memorize the data point.\\
We also see that the norm-based capacity measures are all bigger for random labeled data as the network has to memorize the data whereas the dependence between the input and output can be learned with lower capacity on true labeled data. \par
%
Looking at the sharpness as a capacity measure in \freff{fig:norms-paper} we do not see a direct correlation between its value and the capacity of the network. We expect the model to become less sharp when increasing the network size which can be seen looking at the true labeled data points (blue) but clearly gets violated by the random labeled data points (magenta). Furthermore, we see a lower sharpness for random labels for the two smallest subset sizes which contradicts the intuition that the sharpness should be always lower for true labels. 
%
\subsubsection{Problems reproducing results}
\label{sec:problems-subset-sizes}
\begin{figure}
	\centering
	\includegraphics[width=0.32\linewidth]{vgg16/l2_own.png}
	\includegraphics[width=0.32\linewidth]{vgg16/spectral_own.png}
	\includegraphics[width=0.32\linewidth]{vgg16/sharpness_own.png}
	\caption{Our own results for the $l2$ and spectral norm as well as the sharpness calculated on the VGG-16 model after training on subsets of CIFAR-10. The results show no reproducibility of the results presented by \cite{neyshabur2017exploring}.}	
	\label{fig:norms-own}
\end{figure}
Following the vague instructions of \cite{neyshabur2017exploring} the VGG-16 network with batch normalization \fref{fig:cifar-vgg} is trained on different subsets of the CIFAR-10 \fref{fig:cifar-vgg} data set. For every subset a copy with the labels replaced by random labels has been created and the model is trained on both the true and random labeled subset. \\
%
The huge scope for interpretation of the approach used in \cite{neyshabur2017exploring} caused the non reproducibility of the results which are shown in \freff{fig:norms-own}. The problems we face are:
%
\paragraph{Reproduction of network training}
\label{sec:problems-reproduction-training}
\ns{} only stated that their results were produced using VGG. As VGG is a class of CNN architectures with varying depths and optional batch normalization we performed a grid search over the implementations. Considering the capacity vs. training time trade-of we achieved the best results using VGG-16 with batch normalization.\\
Furthermore, \cite{neyshabur2017exploring} didn't provide information on the used solving strategy. Therefore, we tried simple stochastic gradient descent and Adam but stuck with the later as of the faster convergence.
%
\paragraph{Calculation of norms}
\label{sec:problems-calculation-norms}
The calculation of path norms is trivial for the fully connected case but not for convolutional layers. As we need to enumerate every path through the network we need a way to associate the layer neurons of succeeding layers when applying a convolution. In the short time of this paper we couldn't come up with a feasible implementation which made it impossible to reproduce the path norms.
%
\paragraph{Training on random labeled data}
Following the missing details of the network implementation and solving strategy a training on random labeled data was not possible. The network didn't overcome a $1/10$ test accuracy on random labels which represents a random choice of the result by the network out of the $10$ classes in the CIFAR-10 data set.

\paragraph{Training time}
\label{sec:problems-training-time}
The short scope of the seminar enclosing this paper combined with training times ranging from roughly five hours on the smallest subset ranging up to over one day for the biggest one resulted in only small search intervals for the grid search used on the hyper parameters as well for the algorithmic and architectural choices.
%
\paragraph{Sharpness}
\label{sec:problems-sharpness}
Sharpness as the maximum over the adversarial perturbations is a maximization problem where the difference between the loss of the network with the added perturbation and the original network gets maximized. This maximization problem is constrained on the values of the perturbations and thus requires a constrained optimization strategy. We couldn't come up with such a strategy in the seminars time and thus tried a random search strategy. Due to the high duration of forward passes over the whole training set this random search didn't provide results in a feasible amount of time.
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
\subsection{Difference between local minima}
When training the same architecture, with the same training set, using two different optimization methods (or different algorithmic or parameter choices), one method results in better generalization even though both lead to zero training error. We would
expect to see a correlation between the complexity measure and generalization ability among zero-training error models. \cite{neyshabur2017exploring} \par
%
To drive the network towards different parameter choices \cite{neyshabur2017exploring} proposed to train the VGG network \cite{simonyan2014deep}\fref{fig:cifar-vgg} on a subset of 10000 true labeled data points of the CIFAR-10 \fref{fig:cifar-vgg} and to add confusion sets with varying sizes. A confusion set is a subset of the same data set where the labels are replaced with random labels. When optimizing the network over the union of the true and random labeled sets the resulting optimum has to be optimal for both of the sets.\\
%
We expect to see an increase of the test error with increasing confusion set size as the network not only has to learn the functional dependence between the input and output data but also has to memorize an increasing number of random labeled data points.
This memorization prevents the network from generalizing well and can be seen in \freff{fig:confusion-paper}.\\
%
Following the increase in test error and the resulting worse generalization behavior we expect the capacity measure to increase with the test error. In \freff{fig:confusion-paper} we see this behavior for all the norm-based capacity measures which hints towards them being a valid measure for generalization behavior. But again we see the sharpness to have no direct correlation to the test error which hints that it cannot predict generalization.
%
\begin{figure}
	\centering
	\includegraphics[width=0.32\linewidth]{vgg16/confusion/errors_01.png}
	\includegraphics[width=0.32\linewidth]{vgg16/confusion/measures.png}
	\caption{The test and training error on the subset of CIFAR-10 and varying confusion set sizes (left) and the corresponding proposed capacity measures (right). Reproduced from \cite{neyshabur2017exploring}.}	
	\label{fig:confusion-paper}
\end{figure}
\begin{figure}
\centering
\includegraphics[width=0.32\linewidth]{vgg16/confusion/errors_own.png}
\includegraphics[width=0.32\linewidth]{vgg16/confusion/measures_own.png}
\caption{Our own results for the test and training error on the subset of CIFAR-10 and varying confusion set sizes (left) and the corresponding proposed capacity measures (right).}	
\label{fig:confusion-own}
\end{figure}
%
\subsubsection{Problems reproducing results}
We faced most of the problems already described in \ref{sec:problems-subset-sizes}. Especially the missing model and solving strategy details \ref{sec:problems-reproduction-training} as well as the calculation of the norms \ref{sec:problems-calculation-norms} prevented us from reproducing meaningful results. Nonetheless, the results are displayed in \freff{fig:confusion-own} where we can see an increase of the test error as expected when increasing the subset size. The calculated measures do not follow the expected behavior to increase with the worse generalization ability and sharpness wasn't calculable at all.
%
\paragraph{Training to zero training error not possible}
For the biggest confusion set size training to zero training error was not possible. We tried different optimization strategies and hyper parameters but couldn't drive the model to zero training error.
%
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
\subsection{Implications of different hidden unit sizes}
Increasing the number of hidden units, thereby increasing the number of parameters, can lead to a decrease in generalization error even when the training error does not decrease. We would expect to see the complexity measure decrease as we increase the number of
hidden units. \cite{neyshabur2017exploring} \par
%
To investigate into this phenomenon \ns{} trained a two layer perceptron \fref{fig:mnist-two-layer} on the MNIST handwritten digit data set \fref{fig:mnist-two-layer} using different numbers of hidden units. We see in \ref{fig:hidden-units-paper} that the networks achieve zero training error for 32 and more hidden units and even though there is no decrease in the training error afterwards we see a decrease in the test error with every increase of the hidden units.\\
%
Looking at the capacity measures in \freff{fig:hidden-units-paper} we see that the $l2$-path and spectral norm follow the expected behavior and decrease with the increase of hidden units whereas the $l1$-path norm, the $l2$ norm and sharpness do not behave as proposed.
%
Reproducing the results of \cite{neyshabur2017exploring} put out the values displayed in \freff{fig:hidden-units-own} where we can see that we could achieve a decrease of the $l2$ and $l1$-path norm with the increase of hidden units but see the opposing behavior for the other norms and again no direct correlation between sharpness and generalization behavior.
%
\begin{figure}
	\centering
	\includegraphics[width=0.32\linewidth]{mnist/hidden_units_error.png}
	\includegraphics[width=0.32\linewidth]{mnist/hidden_units_measures.png}
	\caption{The test and training error on the MNIST handwritten digit data set and varying hidden unit sizes (left) and the corresponding proposed capacity measures (right). Reproduced from \cite{neyshabur2017exploring}.}	
	\label{fig:hidden-units-paper}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=0.32\linewidth]{mnist/hidden_units_error_own.png}
	\includegraphics[width=0.32\linewidth]{mnist/hidden_units_measures_own.png}
	\caption{Our own results for the test and training error on the MNIST handwritten digit data set and varying hidden unit sizes (left) and the corresponding proposed capacity measures (right).}	
	\label{fig:hidden-units-own}
\end{figure}













