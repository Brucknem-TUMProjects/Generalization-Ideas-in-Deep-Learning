{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import measures\n",
    "import networks\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "import data_loader\n",
    "from solver import load_solver\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Loading trainings set: cifar10, Batch size: 1, Subset size: 100, Random labels: True\n",
      "Files already downloaded and verified\n",
      "\n********************************************************************************\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "trainings_set = data_loader.get_CIFAR10_dataloader(True, batch_size=1, num_workers=8, download=True, \n",
    "                                                   random_labels=True, subset_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# net = networks.ExampleNet()\n",
    "# net = models.vgg16(pretrained=True)\n",
    "# net = networks.vgg16()\n",
    "\n",
    "solver = load_solver(folder='../brucknem/vgg16_bn_40000_labels/', filename='solver_e_reached_100.pth', verbose=False)\n",
    "solver = load_solver(folder='Seminar/', filename='solver_e_reached_100.pth', verbose=False)\n",
    "\n",
    "net = solver.model\n",
    "params = solver.model_state\n",
    "net.load_state_dict(params)\n",
    "\n",
    "layers = net.state_dict()\n",
    "# pprint(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0\nProcessing layer conv1.weight\nProcessing layer conv1.bias\nSkipping conv1.bias\nProcessing layer conv2.weight\nProcessing layer conv2.bias\nSkipping conv2.bias\nProcessing layer fc1.weight\nProcessing layer fc1.bias\nSkipping fc1.bias\nProcessing layer fc2.weight\nProcessing layer fc2.bias\nSkipping fc2.bias\nProcessing layer fc3.weight\nProcessing layer fc3.bias\nSkipping fc3.bias\n13356268.687418938\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "l2 = norms.l2_norm(net, trainings_set, 0.05)\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0\nProcessing layer conv1.weight\nLayer conv1.weight has no norm. (6, 3, 5, 5)\nProcessing layer conv1.bias\nSkipping conv1.bias\nProcessing layer conv2.weight\nLayer conv2.weight has no norm. (16, 6, 5, 5)\nProcessing layer conv2.bias\nSkipping conv2.bias\nProcessing layer fc1.weight\nProcessing layer fc1.bias\nSkipping fc1.bias\nProcessing layer fc2.weight\nProcessing layer fc2.bias\nSkipping fc2.bias\nProcessing layer fc3.weight\nProcessing layer fc3.bias\nSkipping fc3.bias\n1256753087.6007378\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "spectral = norms.spectral_norm(net, trainings_set, 0.05)\n",
    "print(spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclear_norm = norms.norm_product(layers, 'nuc')\n",
    "print(nuclear_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inf_norm = norms.norm_product(layers, np.linalg.norm, 'inf')\n",
    "#print(inf_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_inf_norm = norms.norm_product(layers, np.linalg.norm, '-inf')\n",
    "#print(min_inf_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#abs_norm = norms.norm_product(layers, np.linalg.norm, 0)\n",
    "#print(abs_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l1_norm = norms.norm_product(layers, 1)\n",
    "print(l1_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_abs_norm = norms.norm_product(layers, -1)\n",
    "print(min_abs_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_singular_norm = norms.norm_product(layers, -2)\n",
    "print(max_singular_norm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}